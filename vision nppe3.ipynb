{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":97753,"databundleVersionId":11639668,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport os\nfrom PIL import Image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:55:17.887796Z","iopub.execute_input":"2025-04-06T10:55:17.888107Z","iopub.status.idle":"2025-04-06T10:55:17.892365Z","shell.execute_reply.started":"2025-04-06T10:55:17.888081Z","shell.execute_reply":"2025-04-06T10:55:17.891430Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, lr_folder, hr_folder, transform=None):\n        self.lr_folder = lr_folder\n        self.hr_folder = hr_folder\n        self.transform = transform\n        self.lr_images = os.listdir(lr_folder)\n        self.hr_images = os.listdir(hr_folder)\n\n    def __len__(self):\n        return len(self.lr_images)\n\n    def __getitem__(self, idx):\n        lr_image = Image.open(os.path.join(self.lr_folder, self.lr_images[idx]))\n        hr_image = Image.open(os.path.join(self.hr_folder, self.hr_images[idx]))\n\n        if self.transform:\n            lr_image = self.transform(lr_image)\n            hr_image = self.transform(hr_image)\n\n        return lr_image, hr_image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:55:18.632417Z","iopub.execute_input":"2025-04-06T10:55:18.632719Z","iopub.status.idle":"2025-04-06T10:55:18.637777Z","shell.execute_reply.started":"2025-04-06T10:55:18.632697Z","shell.execute_reply":"2025-04-06T10:55:18.637038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:55:21.507806Z","iopub.execute_input":"2025-04-06T10:55:21.508141Z","iopub.status.idle":"2025-04-06T10:55:21.512360Z","shell.execute_reply.started":"2025-04-06T10:55:21.508118Z","shell.execute_reply":"2025-04-06T10:55:21.511491Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_lr_folder = '/kaggle/input/dlp-jan-2025-nppe-3/archive/train/train'\ntrain_hr_folder = '/kaggle/input/dlp-jan-2025-nppe-3/archive/train/gt'\neval_lr_folder = '/kaggle/input/dlp-jan-2025-nppe-3/archive/val/val'\neval_hr_folder = '/kaggle/input/dlp-jan-2025-nppe-3/archive/val/gt'\ntest_lr_folder = '/kaggle/input/dlp-jan-2025-nppe-3/archive/test'\n\ntrain_dataset = ImageDataset(train_lr_folder, train_hr_folder, transform=transform)\neval_dataset = ImageDataset(eval_lr_folder, eval_hr_folder, transform=transform)\ntest_dataset = ImageDataset(test_lr_folder, test_lr_folder, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\neval_loader = DataLoader(eval_dataset, batch_size=16, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:55:23.012437Z","iopub.execute_input":"2025-04-06T10:55:23.012776Z","iopub.status.idle":"2025-04-06T10:55:23.022332Z","shell.execute_reply.started":"2025-04-06T10:55:23.012747Z","shell.execute_reply":"2025-04-06T10:55:23.021660Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SRCNN(nn.Module):\n    def __init__(self):\n        super(SRCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=4)\n        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, padding=0)\n        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, padding=2)\n        self.relu = nn.ReLU(inplace=True)\n        self.upsample = nn.Upsample(scale_factor=4, mode='bicubic', align_corners=False)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.conv3(x)\n        x = self.upsample(x)\n        return x\n\nmodel = SRCNN().cuda()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:55:24.487396Z","iopub.execute_input":"2025-04-06T10:55:24.487726Z","iopub.status.idle":"2025-04-06T10:55:24.494705Z","shell.execute_reply.started":"2025-04-06T10:55:24.487702Z","shell.execute_reply":"2025-04-06T10:55:24.494023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:55:26.032273Z","iopub.execute_input":"2025-04-06T10:55:26.032854Z","iopub.status.idle":"2025-04-06T10:55:26.036956Z","shell.execute_reply.started":"2025-04-06T10:55:26.032816Z","shell.execute_reply":"2025-04-06T10:55:26.036153Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 50\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for lr_images, hr_images in train_loader:\n        lr_images = lr_images.cuda()\n        hr_images = hr_images.cuda()\n\n        optimizer.zero_grad()\n        outputs = model(lr_images)\n        loss = criterion(outputs, hr_images)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n\n    # Validation\n    model.eval()\n    eval_loss = 0.0\n    with torch.no_grad():\n        for lr_images, hr_images in eval_loader:\n            lr_images = lr_images.cuda()\n            hr_images = hr_images.cuda()\n            outputs = model(lr_images)\n            loss = criterion(outputs, hr_images)\n            eval_loss += loss.item()\n\n    print(f'Evaluation Loss: {eval_loss/len(eval_loader)}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T10:55:27.187926Z","iopub.execute_input":"2025-04-06T10:55:27.188203Z","iopub.status.idle":"2025-04-06T11:29:57.464382Z","shell.execute_reply.started":"2025-04-06T10:55:27.188183Z","shell.execute_reply":"2025-04-06T11:29:57.463561Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\ntest_predictions = []\nwith torch.no_grad():\n    for lr_images, _ in test_loader:\n        lr_images = lr_images.cuda()\n        outputs = model(lr_images)\n        test_predictions.append(outputs.cpu())\n\ntest_predictions = torch.cat(test_predictions)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:29:57.465707Z","iopub.execute_input":"2025-04-06T11:29:57.466030Z","iopub.status.idle":"2025-04-06T11:29:58.673528Z","shell.execute_reply.started":"2025-04-06T11:29:57.465994Z","shell.execute_reply":"2025-04-06T11:29:58.672852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_folder = '/kaggle/working/test_predictions2'\nos.makedirs(output_folder, exist_ok=True)\n\nfor i, img in enumerate(test_predictions):\n    img = img.permute(1, 2, 0).numpy()\n    img = (img * 0.5) + 0.5  # Unnormalize\n    img = (img * 255).astype(np.uint8)\n    if i < 9:\n        Image.fromarray(img).save(os.path.join(output_folder, f'test_0000{i+1}.png'))\n    else :\n        Image.fromarray(img).save(os.path.join(output_folder, f'test_000{i+1}.png'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:35:27.795857Z","iopub.execute_input":"2025-04-06T11:35:27.796171Z","iopub.status.idle":"2025-04-06T11:35:41.727450Z","shell.execute_reply.started":"2025-04-06T11:35:27.796150Z","shell.execute_reply":"2025-04-06T11:35:41.726575Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model.eval()\n# output_folder = '/kaggle/working/test_predictions'\n# os.makedirs(output_folder, exist_ok=True)\n\n# with torch.no_grad():\n#     for lr_images, _, filenames in test_loader:\n#         lr_images = lr_images.cuda()\n#         outputs = model(lr_images)\n#         outputs = outputs.cpu()\n\n#         for i, img in enumerate(outputs):\n#             img = img.permute(1, 2, 0).numpy()\n#             img = (img * 0.5) + 0.5  # Unnormalize\n#             img = (img * 255).astype(np.uint8)\n#             Image.fromarray(img).save(os.path.join(output_folder, filenames[i]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\ndef images_to_csv(folder_path, output_csv):\n    data_rows = []\n    for filename in os.listdir(folder_path):\n        if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n            image_path = os.path.join(folder_path, filename)\n            image = Image.open(image_path).convert('L') \n            image_array = np.array(image).flatten()[::8]\n            # Replace 'test_' with 'gt_' in the ID\n            image_id = filename.split('.')[0].replace('test_', 'gt_')\n            data_rows.append([image_id, *image_array])\n    column_names = ['ID'] + [f'pixel_{i}' for i in range(len(data_rows[0]) - 1)]\n    df = pd.DataFrame(data_rows, columns=column_names)\n    df.to_csv(output_csv, index=False)\n    print(f'Successfully saved to {output_csv}')\n\nfolder_path = '/kaggle/working/test_predictions2'\noutput_csv = 'submission.csv'\nimages_to_csv(folder_path, output_csv)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T11:36:07.032853Z","iopub.execute_input":"2025-04-06T11:36:07.033153Z","iopub.status.idle":"2025-04-06T11:36:48.876540Z","shell.execute_reply.started":"2025-04-06T11:36:07.033134Z","shell.execute_reply":"2025-04-06T11:36:48.875681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}